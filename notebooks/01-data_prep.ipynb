{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The filepaths in this notebook are no longer valid. This notebook is meant only to be viewed as a reference. All of the code in this notebook has been adapted into [02-data_cleaning.py](./../src/data/02-data_cleaning.py)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_demographics(year_dir_path):\n",
    "    # Find filepath\n",
    "    for subdir, dirs, files in os.walk(year_dir_path + \"Demographics/\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\") & (\"DEMO\" in file):\n",
    "                filepath = os.path.join(subdir, file)\n",
    "\n",
    "    demographics = pd.read_csv(filepath)\n",
    "    dems = demographics[['SEQN', 'RIAGENDR', 'RIDAGEMN', 'RIDAGEYR', 'RIDEXPRG', 'RIDRETH1']].copy()\n",
    "    dems.set_axis(\n",
    "        [\n",
    "            'id',\n",
    "            'sex',                  # 1: Male, 2: Female\n",
    "            'age_months',\n",
    "            'age_yrs',\n",
    "            'pregnancy_status',     # 1: Pregnant, 2: Not pregnant, 3: Unknown\n",
    "            'race'                  \n",
    "        ], \n",
    "        axis=1, \n",
    "        inplace=True\n",
    "    )\n",
    "    dems = dems.astype({\n",
    "        \"id\": \"int\",\n",
    "        \"sex\": \"int\",\n",
    "        \"race\": \"int\"\n",
    "    })\n",
    "    dems.set_index('id', inplace=True)\n",
    "\n",
    "    return dems\n",
    "\n",
    "def import_body_data(body_data_dir_path):\n",
    "    # Find filepath for body data\n",
    "    for subdir, dirs, files in os.walk(body_data_dir_path + \"Examination/\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\") & (\"BMX\" in file):\n",
    "                filepath_measurements = os.path.join(subdir, file)\n",
    "                \n",
    "    # Import body measurements\n",
    "    body_measurements = pd.read_csv(filepath_measurements)\n",
    "    measurements = body_measurements[['SEQN', 'BMXWT', 'BMXHT', 'BMXWAIST']].copy()\n",
    "    measurements.set_axis(['id', 'weight_kg', 'height_cm', 'waist_circum_cm'], axis=1, inplace=True)\n",
    "    measurements = measurements.astype({\"id\": \"int\"})\n",
    "    measurements.set_index('id', inplace=True)\n",
    "\n",
    "    # Drop rows with missing height or weight\n",
    "    measurements = measurements[measurements['weight_kg'].notna() & measurements['height_cm'].notna()]\n",
    "\n",
    "    # Find filepath for body data\n",
    "    for subdir, dirs, files in os.walk(body_data_dir_path + \"Questionnaire/\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\") & ((\"SMQ_\" in file) | (\"SMQ.\" in file)):\n",
    "                filepath_smoker = os.path.join(subdir, file)\n",
    "\n",
    "    # Import smoker indication\n",
    "    smoker_indication = pd.read_csv(filepath_smoker)\n",
    "    smoker = smoker_indication[[\n",
    "        'SEQN', \n",
    "        'SMQ020', # Smoked at least 100 cigarettes in life (1: Yes, 2: No, 7: Refused, 9: Don't know)\n",
    "        'SMQ040'  # Do you know smoke cigarettes (1: Every day, 2: Some days, 3: Not at all, 7: Refused, 9: Don't know)\n",
    "    ]].copy()\n",
    "    smoker.set_axis([\n",
    "        'id', \n",
    "        'has_smoked', \n",
    "        'is_smoker'\n",
    "    ], axis=1, inplace=True)\n",
    "    smoker = smoker.astype({\"id\": \"int\"})\n",
    "    smoker.set_index('id', inplace=True)\n",
    "\n",
    "    # Join smoker and body measurements data\n",
    "    measurements_smoker = pd.merge(measurements, smoker, how='left', on='id')\n",
    "\n",
    "    return measurements_smoker\n",
    "\n",
    "def import_fat_pct(fat_pct_dir_path):\n",
    "    # Find filepath for percent body fat data\n",
    "    for subdir, dirs, files in os.walk(fat_pct_dir_path + \"Examination/\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\") & (\"dxx\" in file):\n",
    "                filepath = os.path.join(subdir, file)\n",
    "\n",
    "    # Import percent body fat data\n",
    "    fat_percentage = pd.read_csv(filepath)\n",
    "    fat_pct = fat_percentage[['SEQN', '_MULT_', 'DXDTOPF']]\n",
    "    fat_pct.set_axis(['id', 'M', 'total_fat_pct'], axis=1, inplace=True)\n",
    "    fat_pct = fat_pct.astype({\"id\": \"int\", \"M\": \"int\"})\n",
    "\n",
    "    # Drop rows with missing data\n",
    "    # fat_pct = fat_pct[fat_pct['total_fat_pct'].notna()]\n",
    "\n",
    "\n",
    "    return fat_pct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_year_predictors(year_range):\n",
    "    # Import predictors\n",
    "    demographics = import_demographics(\"./../../../Data/NHANES_\" + year_range + \"/\")\n",
    "    measurements = import_body_data(\"./../../../Data/NHANES_\" + year_range + \"/\")\n",
    "\n",
    "    # Join demographic and measurement data\n",
    "    predictors = pd.merge(measurements, demographics, how='left', on='id')\n",
    "\n",
    "    return predictors\n",
    "\n",
    "def import_predictors():\n",
    "    # Import datasets from each year\n",
    "    predictors99 = import_year_predictors(\"1999-2000\")\n",
    "    predictors99['years'] = \"1999-2000\"\n",
    "    predictors01 = import_year_predictors(\"2001-2002\")\n",
    "    predictors01['years'] = \"2001-2002\"\n",
    "    predictors03 = import_year_predictors(\"2003-2004\")\n",
    "    predictors03['years'] = \"2003-2004\"\n",
    "    predictors05 = import_year_predictors(\"2005-2006\")\n",
    "    predictors05['years'] = \"2005-2006\"\n",
    "\n",
    "    # Concatenate all datasets into one\n",
    "    predictors = pd.concat([predictors99, predictors01, predictors03, predictors05], axis=0)\n",
    "\n",
    "    # CLEANING\n",
    "    predictors['sex'] = predictors['sex'] - 1\n",
    "\n",
    "    return predictors\n",
    "\n",
    "def import_response():\n",
    "    # Import fat_pct from each year\n",
    "    response99 = import_fat_pct(\"./../../../Data/NHANES_1999-2000/\")\n",
    "    response01 = import_fat_pct(\"./../../../Data/NHANES_2001-2002/\")\n",
    "    response03 = import_fat_pct(\"./../../../Data/NHANES_2003-2004/\")\n",
    "    response05 = import_fat_pct(\"./../../../Data/NHANES_2005-2006/\")\n",
    "\n",
    "    # Concatenate all datasets into one\n",
    "    response = pd.concat([response99, response01, response03, response05], axis=0)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join imputed values onto predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = import_predictors()\n",
    "predictors.to_csv(\"./data/predictors.csv\")\n",
    "response = import_response()\n",
    "response.to_csv(\"./data/response.csv\")\n",
    "\n",
    "# M = 1\n",
    "responseM1 = response.copy()[response['M'] == 1]\n",
    "responseM1.set_index('id', inplace=True)\n",
    "dataM1 = pd.merge(predictors.copy(), responseM1, how=\"inner\", on=\"id\")\n",
    "dataM1.to_csv(\"./data/M1_data.csv\")\n",
    "\n",
    "# M = 2\n",
    "responseM2 = response.copy()[response['M'] == 2]\n",
    "responseM2.set_index('id', inplace=True)\n",
    "dataM2 = pd.merge(predictors.copy(), responseM2, how=\"inner\", on=\"id\")\n",
    "dataM2.to_csv(\"./data/M2_data.csv\")\n",
    "\n",
    "# M = 3\n",
    "responseM3 = response.copy()[response['M'] == 3]\n",
    "responseM3.set_index('id', inplace=True)\n",
    "dataM3 = pd.merge(predictors.copy(), responseM3, how=\"inner\", on=\"id\")\n",
    "dataM3.to_csv(\"./data/M3_data.csv\")\n",
    "\n",
    "# M = 4\n",
    "responseM4 = response.copy()[response['M'] == 4]\n",
    "responseM4.set_index('id', inplace=True)\n",
    "dataM4 = pd.merge(predictors.copy(), responseM4, how=\"inner\", on=\"id\")\n",
    "dataM4.to_csv(\"./data/M4_data.csv\")\n",
    "\n",
    "# M = 5\n",
    "responseM5 = response.copy()[response['M'] == 5]\n",
    "responseM5.set_index('id', inplace=True)\n",
    "dataM5 = pd.merge(predictors.copy(), responseM5, how=\"inner\", on=\"id\")\n",
    "dataM5.to_csv(\"./data/M5_data.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run transformation on smoking columns and re-export datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CODE IS TAKEN FROM \"eda.ipynb\"\n",
    "predictors_smoking = predictors.copy()\n",
    "\n",
    "# Drop 'age_months' since there is no missing data in age_yrs\n",
    "predictors_smoking.drop(['age_months'], axis=1, inplace=True)\n",
    "\n",
    "# Construct 'smoker_status' column\n",
    "predictors_smoking['smoker_status'] = np.nan\n",
    "\n",
    "# Set 'smoker_status' column to 0 for non-smokers (who have never been smokers)\n",
    "predictors_smoking.loc[predictors_smoking['has_smoked'] == 2, 'smoker_status'] = 0\n",
    "\n",
    "# Set 'smoker_status' column to 1 for active smokers\n",
    "predictors_smoking.loc[(predictors_smoking['is_smoker'] == 1) | (predictors_smoking['is_smoker'] == 2), 'smoker_status'] = 1\n",
    "\n",
    "# Set 'smoker_status' column to 2 for former smokers\n",
    "predictors_smoking.loc[predictors_smoking['is_smoker'] == 3, 'smoker_status'] = 2\n",
    "\n",
    "# Drop 'has_smoked' and 'is_smoker' columns now that they are consolidated into 'smoker_status'\n",
    "predictors_smoking.drop(['has_smoked', 'is_smoker'], axis=1, inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "cols_reordered = [\n",
    "    'weight_kg', \n",
    "    'height_cm', \n",
    "    'sex', \n",
    "    'age_yrs', \n",
    "    'race', \n",
    "    'waist_circum_cm', \n",
    "    'smoker_status', \n",
    "    'pregnancy_status', \n",
    "    'years'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update predictors dataset and rerun code joining each imputation on the response\n",
    "predictors = predictors_smoking[cols_reordered]\n",
    "\n",
    "predictors.to_csv(\"./data_smokercleaned/predictors.csv\")\n",
    "\n",
    "response.to_csv(\"./data_smokercleaned/response.csv\")\n",
    "\n",
    "# M = 1\n",
    "responseM1 = response.copy()[response['M'] == 1]\n",
    "responseM1.set_index('id', inplace=True)\n",
    "dataM1 = pd.merge(predictors.copy(), responseM1, how=\"inner\", on=\"id\")\n",
    "dataM1.to_csv(\"./data_smokercleaned/M1_data.csv\")\n",
    "\n",
    "# M = 2\n",
    "responseM2 = response.copy()[response['M'] == 2]\n",
    "responseM2.set_index('id', inplace=True)\n",
    "dataM2 = pd.merge(predictors.copy(), responseM2, how=\"inner\", on=\"id\")\n",
    "dataM2.to_csv(\"./data_smokercleaned/M2_data.csv\")\n",
    "\n",
    "# M = 3\n",
    "responseM3 = response.copy()[response['M'] == 3]\n",
    "responseM3.set_index('id', inplace=True)\n",
    "dataM3 = pd.merge(predictors.copy(), responseM3, how=\"inner\", on=\"id\")\n",
    "dataM3.to_csv(\"./data_smokercleaned/M3_data.csv\")\n",
    "\n",
    "# M = 4\n",
    "responseM4 = response.copy()[response['M'] == 4]\n",
    "responseM4.set_index('id', inplace=True)\n",
    "dataM4 = pd.merge(predictors.copy(), responseM4, how=\"inner\", on=\"id\")\n",
    "dataM4.to_csv(\"./data_smokercleaned/M4_data.csv\")\n",
    "\n",
    "# M = 5\n",
    "responseM5 = response.copy()[response['M'] == 5]\n",
    "responseM5.set_index('id', inplace=True)\n",
    "dataM5 = pd.merge(predictors.copy(), responseM5, how=\"inner\", on=\"id\")\n",
    "dataM5.to_csv(\"./data_smokercleaned/M5_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (v3.9.13:6de2ca5339, May 17 2022, 11:37:23) \n[Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
